{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.profiler.internal import flops_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script adapts the flops counter from the tensorflow profiler to ensure that\n",
    "# it correctly estimates the flops reequired for complex-valued ops.\n",
    "# \n",
    "# NOTE:\n",
    "# I am only adapting the flops counter for a subset of the ops implemented in Tensorflow,\n",
    "# i.e. only the ops I actually use with complex numbers.\n",
    "#\n",
    "# Adapted from:\n",
    "# https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/profiler/internal/flops_registry.py\n",
    "# and\n",
    "# https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/ops.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegisterStatistics(object):\n",
    "    \"\"\"A decorator for registering the statistics function for an op type.\n",
    "    This decorator can be defined for an op type so that it gives a\n",
    "    report on the resources used by an instance of an operator, in the\n",
    "    form of an OpStats object.\n",
    "    Well-known types of statistics include these so far:\n",
    "    - flops: When running a graph, the bulk of the computation happens doing\n",
    "    numerical calculations like matrix multiplications. This type allows a node\n",
    "    to return how many floating-point operations it takes to complete. The\n",
    "    total number of FLOPs for a graph is a good guide to its expected latency.\n",
    "    You can add your own statistics just by picking a new type string, registering\n",
    "    functions for the ops you care about, and then calling get_stats_for_node_def.\n",
    "    If a statistic for an op is registered multiple times, a KeyError will be\n",
    "    raised.\n",
    "    Since the statistics is counted on a per-op basis. It is not suitable for\n",
    "    model parameters (capacity), which is expected to be counted only once, even\n",
    "    if it is shared by multiple ops. (e.g. RNN)\n",
    "    For example, you can define a new metric called doohickey for a Foo operation\n",
    "    by placing this in your code:\n",
    "    ```python\n",
    "    @ops.RegisterStatistics(\"Foo\", \"doohickey\")\n",
    "    def _calc_foo_bojangles(unused_graph, unused_node_def):\n",
    "    return ops.OpStats(\"doohickey\", 20)\n",
    "    ```\n",
    "    Then in client code you can retrieve the value by making this call:\n",
    "    ```python\n",
    "    doohickey = ops.get_stats_for_node_def(graph, node_def, \"doohickey\")\n",
    "    ```\n",
    "    If the NodeDef is for an op with a registered doohickey function, you'll get\n",
    "    back the calculated amount in doohickey.value, or None if it's not defined.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, op_type: str,\n",
    "                 statistic_type: str):\n",
    "        \"\"\"Saves the `op_type` as the `Operation` type.\"\"\"\n",
    "        if not isinstance(op_type, six.string_types):\n",
    "            raise TypeError(\"op_type must be a string.\")\n",
    "        if \",\" in op_type:\n",
    "            raise TypeError(\"op_type must not contain a comma.\")\n",
    "        self._op_type = op_type\n",
    "        if not isinstance(statistic_type, six.string_types):\n",
    "            raise TypeError(\"statistic_type must be a string.\")\n",
    "        if \",\" in statistic_type:\n",
    "            raise TypeError(\"statistic_type must not contain a comma.\")\n",
    "        self._statistic_type = statistic_type\n",
    "\n",
    "    def __call__(self, f):\n",
    "        \"\"\"Registers \"f\" as the statistics function for \"op_type\".\n",
    "        \n",
    "        If the \"op_type\" already exists in the registry, \n",
    "        then replace the flops counter for that \"op_type\".\"\"\"\n",
    "        op_str = self._op_type + \",\" + self._statistic_type\n",
    "        if op_str in ops._stats_registry._registry:\n",
    "            del ops._stats_registry._registry[op_str]\n",
    "        ops._stats_registry.register(f, op_str)\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@RegisterStatistics(\"Square\", \"flops\")\n",
    "def _square_flops(graph, node):\n",
    "    \"\"\"Compute flops for Square operation.\"\"\"\n",
    "    if node.attr['T'].type == tf.complex64:\n",
    "        ops_per_element = 6\n",
    "    else:\n",
    "        ops_per_element = 1\n",
    "    return flops_registry._unary_op_flops(graph, node, ops_per_element=ops_per_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@RegisterStatistics(\"Reciprocal\", \"flops\")\n",
    "def _reciprocal_flops(graph, node):\n",
    "    \"\"\"Compute flops for Reciprocal operation.\"\"\"\n",
    "    if node.attr['T'].type == tf.complex64:\n",
    "        ops_per_element = 6\n",
    "    else:\n",
    "        ops_per_element = 1\n",
    "    return flops_registry._unary_op_flops(graph, node, ops_per_element=ops_per_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@RegisterStatistics(\"Neg\", \"flops\")\n",
    "def _neg_flops(graph, node):\n",
    "    \"\"\"Compute flops for Neg operation.\"\"\"\n",
    "    if node.attr['T'].type == tf.complex64:\n",
    "        ops_per_element = 2\n",
    "    else:\n",
    "        ops_per_element = 1\n",
    "    return flops_registry._unary_op_flops(graph, node, ops_per_element=ops_per_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@RegisterStatistics(\"AssignSub\", \"flops\")\n",
    "def _assign_sub_flops(graph, node):\n",
    "    \"\"\"Compute flops for AssignSub operation.\"\"\"\n",
    "    if node.attr['T'].type == tf.complex64:\n",
    "        ops_per_element = 2\n",
    "    else:\n",
    "        ops_per_element = 1\n",
    "    return flops_registry._unary_op_flops(graph, node, ops_per_element=ops_per_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@RegisterStatistics(\"AssignAdd\", \"flops\")\n",
    "def _assign_add_flops(graph, node):\n",
    "    \"\"\"Compute flops for AssignAdd operation.\"\"\"\n",
    "    if node.attr['T'].type == tf.complex64:\n",
    "        ops_per_element = 2\n",
    "    else:\n",
    "        ops_per_element = 1\n",
    "    return flops_registry._unary_op_flops(graph, node, ops_per_element=ops_per_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@RegisterStatistics(\"Conj\", \"flops\")\n",
    "def _conj_flops(graph, node):\n",
    "    \"\"\"Compute flops for Conj operation.\"\"\"\n",
    "    return flops_registry._unary_op_flops(graph, node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@RegisterStatistics(\"Abs\", \"flops\")\n",
    "def _abs_flops(graph, node):\n",
    "    \"\"\"Compute flops for Abs operation.\"\"\"\n",
    "    # mul, sqrt\n",
    "    return flops_registry._unary_op_flops(graph, node, ops_per_element=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@RegisterStatistics(\"ComplexAbs\", \"flops\")\n",
    "def _complex_abs_flops(graph, node):\n",
    "    \"\"\"Compute flops for Abs operation.\"\"\"\n",
    "    # conj, mul, sqrt\n",
    "    return flops_registry._unary_op_flops(graph, node, ops_per_element=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Binary operations\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@RegisterStatistics(\"Add\", \"flops\")\n",
    "def _add_flops(graph, node):\n",
    "    \"\"\"Compute flops for Add operation.\"\"\"\n",
    "    if node.attr['T'].type == tf.complex64:\n",
    "        ops_per_element = 2\n",
    "    else:\n",
    "        ops_per_element = 1\n",
    "    return flops_registry._binary_per_element_op_flops(graph, node, ops_per_element=ops_per_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@RegisterStatistics(\"Sub\", \"flops\")\n",
    "def _sub_flops(graph, node):\n",
    "    \"\"\"Compute flops for Sub operation.\"\"\"\n",
    "    if node.attr['T'].type == tf.complex64:\n",
    "        ops_per_element = 2\n",
    "    else:\n",
    "        ops_per_element = 1\n",
    "    return flops_registry._binary_per_element_op_flops(graph, node, ops_per_element=ops_per_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@RegisterStatistics(\"Mul\", \"flops\")\n",
    "def _mul_flops(graph, node):\n",
    "    \"\"\"Compute flops for Mul operation.\"\"\"\n",
    "    if node.attr['T'].type == tf.complex64:\n",
    "        ops_per_element = 6\n",
    "    else:\n",
    "        ops_per_element = 1\n",
    "    return flops_registry._binary_per_element_op_flops(graph, node, ops_per_element=ops_per_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@RegisterStatistics(\"RealDiv\", \"flops\")\n",
    "def _real_div_flops(graph, node):\n",
    "    \"\"\"Compute flops for RealDiv operation.\"\"\"\n",
    "    if node.attr['T'].type == tf.complex64:\n",
    "        ops_per_element = 6\n",
    "    else:\n",
    "        ops_per_element = 1\n",
    "    return flops_registry._binary_per_element_op_flops(graph, node, ops_per_element=ops_per_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@RegisterStatistics(\"Pow\", \"flops\")\n",
    "def _pow_flops(graph, node):\n",
    "    \"\"\"Compute flops for Pow operation.\"\"\"\n",
    "    if node.attr['T'].type == tf.complex64:\n",
    "        ops_per_element = 6\n",
    "    else:\n",
    "        ops_per_element = 1\n",
    "    return flops_registry._binary_per_element_op_flops(graph, node, ops_per_element=ops_per_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Reduction ops\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@RegisterStatistics(\"Mean\", \"flops\")\n",
    "def _mean_flops(graph, node):\n",
    "    \"\"\"Compute flops for Mean operation.\"\"\"\n",
    "    # reduction - sum, finalization - divide\n",
    "    if node.attr['T'].type == tf.complex64:\n",
    "        reduce_flops = 2\n",
    "        finalize_flops = 2\n",
    "    else:\n",
    "        reduce_flops = 1\n",
    "        finalize_flops = 1\n",
    "    return flops_registry._reduction_op_flops(graph, node, reduce_flops=reduce_flops, finalize_flops=finalize_flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@RegisterStatistics(\"Sum\", \"flops\")\n",
    "def _sum_flops(graph, node):\n",
    "    \"\"\"Compute flops for Sum operation.\"\"\"\n",
    "    # reduction - sum, no finalization\n",
    "    if node.attr['T'].type == tf.complex64:\n",
    "        reduce_flops = 2\n",
    "        finalize_flops = 0\n",
    "    else:\n",
    "        reduce_flops = 1\n",
    "        finalize_flops = 0\n",
    "    return flops_registry._reduction_op_flops(graph, node, reduce_flops=reduce_flops, finalize_flops=finalize_flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@RegisterStatistics(\"Prod\", \"flops\")\n",
    "def _prod_flops(graph, node):\n",
    "    \"\"\"Compute flops for Prod operation.\"\"\"\n",
    "    # reduction - sum, no finalization\n",
    "    if node.attr['T'].type == tf.complex64:\n",
    "        reduce_flops = 6\n",
    "        finalize_flops = 0\n",
    "    else:\n",
    "        reduce_flops = 1\n",
    "        finalize_flops = 0\n",
    "    return flops_registry._reduction_op_flops(graph, node, reduce_flops=reduce_flops, finalize_flops=finalize_flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@RegisterStatistics(\"BiasAddGrad\", \"flops\")\n",
    "def _bias_add_grad_flops(graph, node):\n",
    "    \"\"\"Compute flops for BiasAddGrad operation.\"\"\"\n",
    "    # Implementation of BiasAddGrad, essentially it's a reduce sum and reshaping:\n",
    "    # So computing flops same way as for \"Sum\"\n",
    "    if node.attr['T'].type == tf.complex64:\n",
    "        reduce_flops = 2\n",
    "        finalize_flops = 0\n",
    "    else:\n",
    "        reduce_flops = 1\n",
    "        finalize_flops = 0\n",
    "    return flops_registry._reduction_op_flops(graph, node, reduce_flops=reduce_flops, finalize_flops=finalize_flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@RegisterStatistics(\"AddN\", \"flops\")\n",
    "def _add_n_flops(graph, node):\n",
    "    \"\"\"Compute flops for AddN operation.\"\"\"\n",
    "    if not node.input:\n",
    "        return _zero_flops(graph, node)\n",
    "    in_shape = graph_util.tensor_shape_from_node_def_name(graph, node.input[0])\n",
    "    in_shape.assert_is_fully_defined()\n",
    "    if node.attr['T'].type == tf.complex64:\n",
    "        flops_per_element = 2\n",
    "    else:\n",
    "        flops_per_element = 1\n",
    "    return ops.OpStats(\"flops\", in_shape.num_elements() * flops_per_element * (len(node.input) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@RegisterStatistics(\"FFT2D\", \"flops\")\n",
    "def _fft_2d_flops(graph, node):\n",
    "    \"\"\"Compute flops for fft2d operation.\n",
    "    \n",
    "    The radix-2 Cooley-Tukey algorithm asymptotically requires 5 N log2(N) floating-point operations.\n",
    "    I am using this value as the flops estimate.\n",
    "    \n",
    "    Source:\n",
    "    http://www.fftw.org/speed/method.html\n",
    "    \"\"\"\n",
    "    if not node.input:\n",
    "        return _zero_flops(graph, node)\n",
    "    in_shape = graph_util.tensor_shape_from_node_def_name(graph, node.input[0])\n",
    "    in_shape.assert_is_fully_defined()\n",
    "    n = in_shape.num_elements()\n",
    "    num_ops = np.int_(np.ceil(5 * n * np.log2(n)))\n",
    "    return ops.OpStats(\"flops\", num_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@RegisterStatistics(\"IFFT2D\", \"flops\")\n",
    "def _ifft_2d_flops(graph, node):\n",
    "    \"\"\"Compute flops for ifft2d operation.\n",
    "    \n",
    "    Using same value as in fft2d\"\"\"\n",
    "    if not node.input:\n",
    "        return _zero_flops(graph, node)\n",
    "    in_shape = graph_util.tensor_shape_from_node_def_name(graph, node.input[0])\n",
    "    in_shape.assert_is_fully_defined()\n",
    "    n = in_shape.num_elements()\n",
    "    num_ops = np.int_(np.ceil(5 * n * np.log2(n)))\n",
    "    return ops.OpStats(\"flops\", num_ops)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
